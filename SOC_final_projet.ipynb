{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bdOpqeg-HKgf"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, Conv2DTranspose, Concatenate, MaxPooling2D, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdEoyT9Iadzp"
      },
      "source": [
        "Dataset Link: https://www.kaggle.com/datasets/theblackmamba31/landscape-image-colorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "raZ6yNp8fvkn"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 \n",
        "img_size = 120\n",
        "subset_split = 2500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert Color image into LAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7HMAYvOlIL1a"
      },
      "outputs": [],
      "source": [
        "# #Convert image into LAB\n",
        "\n",
        "dire = r\"C:\\Users\\nasir\\Downloads\\archive_extracted\\landscape Images\\color\"\n",
        "x = []\n",
        "y = []\n",
        "for image_file in os.listdir( dire )[ 0 : subset_split ]:\n",
        "    rgb_image = Image.open( os.path.join( dire , image_file ) ).resize( ( img_size , img_size ) )\n",
        "    rgb_img_array = (np.asarray( rgb_image ) ) / 255\n",
        "    gray_image = rgb_image.convert( 'L' )\n",
        "    gray_img_array = ( np.asarray( gray_image ).reshape( ( img_size , img_size , 1 ) ) ) / 255\n",
        "    x.append( gray_img_array )\n",
        "    y.append( rgb_img_array )\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split( np.array(x) , np.array(y) , test_size=0.1 )\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices( ( train_x , train_y ) )\n",
        "dataset = dataset.batch( batch_size )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UtZlFkCbZtRa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def generator_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(16, kernel_size=(5, 5), strides=1, input_shape=(img_size, img_size, 1)),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(32, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(32, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2D(32, kernel_size=(5, 5), strides=1),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(64, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(64, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2D(64, kernel_size=(5, 5), strides=1),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(128, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "        Conv2D(128, kernel_size=(3, 3), strides=1),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2D(128, kernel_size=(3, 3), strides=1, activation='tanh', padding='same'),\n",
        "\n",
        "        Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(64, kernel_size=(5, 5), strides=1, activation='relu'),\n",
        "\n",
        "        Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(32, kernel_size=(5, 5), strides=1, activation='relu'),\n",
        "\n",
        "        Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2DTranspose(3, kernel_size=(5, 5), strides=1, activation='relu')\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Io0kwJlEZuvP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def discriminator_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu', input_shape=(120, 120, 3)),\n",
        "        Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(64, kernel_size=(5, 5), strides=1, activation='relu'),\n",
        "        Conv2D(64, kernel_size=(5, 5), strides=1, activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2D(128, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        Conv2D(256, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JrgZScMdLUhE"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output , real_y):\n",
        "    real_y = tf.cast( real_y , 'float32' )\n",
        "    return mse( fake_output , real_y )\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9GMSTlUe6yY",
        "outputId": "bf4bd20f-1f03-4fc6-c7fe-6c59150d29df"
      },
      "outputs": [],
      "source": [
        "generator = generator_model()\n",
        "discriminator = discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k3Zz0OPpLlGZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step( input_x , real_y ):\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator( input_x , training=True)\n",
        "        real_output = discriminator( real_y, training=True)\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "        gen_loss = generator_loss( generated_images , real_y )\n",
        "        disc_loss = discriminator_loss( real_output, generated_output )\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4LLO0RmL8U1",
        "outputId": "f5c386cd-cdda-4ef9-b627-19d17c75b7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n",
            "(10, 120, 120, 1)\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 120\n",
        "\n",
        "for e in range( num_epochs ):\n",
        "    print( e )\n",
        "    for ( x , y ) in dataset:\n",
        "\n",
        "        print( x.shape )\n",
        "        train_step( x , y )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = generator( test_x[0 : ] ).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-MCBuP56MPt1"
      },
      "outputs": [],
      "source": [
        "for i in range(len(test_x)):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  or_image = plt.subplot(3,3,1)\n",
        "  or_image.set_title('Grayscale Image', fontsize=16)\n",
        "  plt.imshow( test_x[i].reshape((120,120)) , cmap='gray' )\n",
        "\n",
        "  in_image = plt.subplot(3,3,2)\n",
        "  image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  image = np.asarray( image )\n",
        "  in_image.set_title('Colorized Image', fontsize=16)\n",
        "  plt.imshow( image ) \n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "#Due To Low Gpu in my device I cannot train the model properly For checking please train it properly and then use it"
        **And second thing is that after train and comparing  the input and output image the file was becaming 45MB which is exceeding 25MB so I cannot upload in GITHUB**
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
